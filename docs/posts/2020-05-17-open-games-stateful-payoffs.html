<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Jules Hedges - Open games with stateful payoffs</title>
        <link rel="stylesheet" href="../css/default.css" />
        <link rel="stylesheet" href="../css/syntax.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../">Jules Hedges</a>
            </div>
            <nav>
                <a href="../">Home</a>
                <a href="../papers.html">Papers</a>
                <a href="../blog.html">Blog</a>
                <a href="../forest/index.html">Forest</a>
                <a href="../links.html">Links</a>
            </nav>
        </header>

        <main role="main">
            <h1>Open games with stateful payoffs</h1>
            <article>
    <section class="header">
        Posted on May 17, 2020
        
    </section>
    <section>
        <p>I‚Äôm starting to worry that <a href="https://github.com/CyberCat-Institute/open-game-engine">my open games implementation</a> is getting ahead of what I‚Äôve written in papers in a few ways, and I should correct that with documentation blog posts. This one is about the module <a href="https://github.com/CyberCat-Institute/open-game-engine/blob/og-v0.1/src/OpenGames/Engine/StatefulPayoffs.hs"><code>OpenGames.Engine.StatefulPayoffs</code></a>, which is a pragmatic solution to a fundamental conceptual problem with open games: the identity of agents is not well-defined. Rather the fundamental unit is a decision, and if two decisions are made by the same agent then it is the user‚Äôs responsibility to make sure that those decisions have the same payoff, or at least game-theoretically ‚Äúcoherent‚Äù payoffs.</p>
<p>For a long time I thought this was a conceptual problem but not a practical one. But recent work with my collaborators Philipp Zahn, Seth Frey and Joshua Tan has stress-tested open games in new ways and revealed it to a problem after all.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Specifically, if one agent makes 2 decisions on different sides of an abstraction boundary, then the programmer must explicitly design the boundary to accommodate that agent‚Äôs payoff. This feels like an abstraction leak.</p>
<p>The solution I came up with is to put the backwards part of an open game into a state monad, so that different decisions made by the same agent implicitly coordinate through a global stable variable. Loosely speaking, this means augmenting an open game with an imperative program that runs backwards in time and transforms payoffs. I find it neat that the state monad is normally used to describe something non-compositional in programming, namely mutable global state, and it can also be used to describe something non-compositional in game theory, namely that an agents‚Äô identities cut across the structure of a game.</p>
<p>The main technical component is <em>monadic lenses</em>, due to <a href="https://arxiv.org/abs/1601.02484">this paper</a>. (They are the simplest example of a <a href="https://arxiv.org/abs/2001.07488">mixed optic</a>.) A monadic lens <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>T</mi><mo stretchy="false" form="postfix">)</mo><mo>‚Üí</mo><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(S, T) \to (A, B)</annotation></semantics></math> for the monad <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> consists of a view function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>‚Üí</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">S \to A</annotation></semantics></math> and an update function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>√ó</mo><mi>B</mi><mo>‚Üí</mo><mi>M</mi><mi>T</mi></mrow><annotation encoding="application/x-tex">S \times B \to M T</annotation></semantics></math>, thus the update (but not the view) lives in the kleisli category. (Putting view in the kleisli category is much harder, and requires passing from lenses to optics, as we do in Bayesian open games.) Monadic lenses compose in an entirely obvious way to form a category, which is a monoidal category if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> is commutative (see <a href="../posts/2019-04-18-folklore-monoidal-kleisli-categories.html">monoidal kleisli categories</a>).</p>
<p>Of course we take <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> to be a state monad, which is not commutative, which means that lenses only form a <a href="https://ncatlab.org/nlab/show/premonoidal+category">premonoidal category</a>. This isn‚Äôt a problem in practice because my implementation uses a sequential DSL that can‚Äôt directly express simultaneous play, just like do-notation.</p>
<p>We take the type of the state variable to be the type of payoff vectors, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùíú</mi><mo>‚Üí</mo><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">\mathcal{A} \to \mathbb{R}</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùíú</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math> is the type of agents. In practice, so far I‚Äôve taken the type of agents to be <code>String</code>, so an agent‚Äôs identity is its name and I don‚Äôt have to worry about how to modify <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùíú</mi><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math> when embedding a game into a context with more agents. (It should probably be a <code>Data.Map</code>, but performance isn‚Äôt important here so I just used a function.)</p>
<p>The appropriate type of contexts for an open game <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>S</mi><mo>,</mo><mi>T</mi><mo stretchy="false" form="postfix">)</mo><mo>‚Üí</mo><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(S, T) \to (A, B)</annotation></semantics></math> when using monadic lenses turns out to be the obvious thing, namely <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>√ó</mo><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mo>‚Üí</mo><mi>M</mi><mi>B</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">S \times (A \to M B)</annotation></semantics></math>. With this, open games can be defined and they form a premonoidal category.</p>
<p>The interesting part is how to define decisions, which now involves a lot of moving parts. A decision is an open game of type <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo><mo>‚Üí</mo><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>,</mo><mi>‚Ñù</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(X, 1) \to (Y, \mathbb{R})</annotation></semantics></math>, and we fix an agent <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>‚àà</mo><mi>ùíú</mi></mrow><annotation encoding="application/x-tex">a \in \mathcal{A}</annotation></semantics></math> making the decision. The strategies are still <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>‚Üí</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">X \to Y</annotation></semantics></math> as usual. For a fixed strategy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo>:</mo><mi>X</mi><mo>‚Üí</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\sigma : X \to Y</annotation></semantics></math>, the forwards part of the resulting lens is just <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÉ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math>.</p>
<p>The backwards part is a function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>√ó</mo><mi>‚Ñù</mi><mo>‚Üí</mo><mi>M</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">X \times \mathbb{R} \to M 1</annotation></semantics></math>. Usually for a decision this coplay function is trivial, but here we instead do something creative: we take the agent <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>‚Äòs existing payoff from the state variable, and we numerically <em>add</em> the payoff of the decision. There are two aspects of this: Why modify the payoff, and why add it in particular?</p>
<p>The second thing is easy: I had to do something, and guessed that addition was probably going to be the most useful in practice. The first thing is subtle. Because the imperative code is running backwards in time (contravariantly), the decision is modifying the payoff of past decisions by the same agent. This works because payoffs in the past are like sunk costs: an agent is indifferent to anything you do to its payoff in the past (and dually, an imperative program‚Äôs behaviour is independent of changes made to its state in the future). I don‚Äôt think it‚Äôs obvious that this hack works, but it does seem to work.</p>
<p>The most complicated part is the equilibrium check. We are given a context <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>h</mi><mo>,</mo><mi>k</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(h, k)</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>‚àà</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">h \in X</annotation></semantics></math> is the history and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>:</mo><mi>Y</mi><mo>‚Üí</mo><mi>M</mi><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">k : Y \to M \mathbb{R}</annotation></semantics></math> is the continuation. We convert <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> into an ordinary function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mo>‚Ä≤</mo></msup><mo>:</mo><mi>Y</mi><mo>‚Üí</mo><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">k' : Y \to \mathbb{R}</annotation></semantics></math> by escaping the state monad: we initialise the state with the identically zero payoff vector, and then at the end we add the final value of agent <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>‚Äòs state variable to the return value to produce the total payoff (throwing away the payoffs of the other agents).</p>
<p>From here$ it‚Äôs business as usual, we check whether <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo stretchy="false" form="prefix">(</mo><mi>h</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\sigma (h)</annotation></semantics></math> maximises <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mo>‚Ä≤</mo></msup><annotation encoding="application/x-tex">k'</annotation></semantics></math>. In practice this means querying <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mo>‚Ä≤</mo></msup><annotation encoding="application/x-tex">k'</annotation></semantics></math> at every counterfactual value <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>, and each of these means rerunning the imperative program with a different input and a re-initialised state. (Thus it acts like a global state to coplay, but only a local state to the equilibrium checker.)</p>
<p>We can do some other tricks too. Obviously we can nonlocally modify an agent‚Äôs payoff without any decision being made. (One application I have in mind for this is discounting.) My favourite of these is decisions which are not made by a fixed agent, but by one decided endogenously, something that would otherwise be a pain to express (using external choice, probably the subject of a future blog post).</p>
<p>Specifically, we can make a variant decision (which we call a ‚Äòrole decision‚Äô) of type <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>ùíú</mi><mo>√ó</mo><mi>X</mi><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo><mo>‚Üí</mo><mo stretchy="false" form="prefix">(</mo><mi>Y</mi><mo>,</mo><mi>‚Ñù</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mathcal{A} \times X, 1) \to (Y, \mathbb{R})</annotation></semantics></math> whose set of strategies is still <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>‚Üí</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">X \to Y</annotation></semantics></math> (although I have an idea to extend this to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùíú</mi><mo>√ó</mo><mi>X</mi><mo>‚Üí</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\mathcal{A} \times X \to Y</annotation></semantics></math>, allowing each agent to have a different contingent strategy for if they are chosen to make the decision). The equilibrium checker now takes a state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>k</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(a, h, k)</annotation></semantics></math>, and this variable <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> is used to index into the state vector.</p>
<p>The main thing on the todo list is to make this work for Bayesian games, since it currently only works for pure strategies (in turn, because monadic lenses are easier to understand). I expect this to start from mixed optics where the forwards part lives in the kleisli category of probability, and the backwards part lives in the kleisli category of the monad transformer stack consisting of probability below and state above.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Editor‚Äôs note: This is the work that eventually led to <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0283361">this paper</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>Editor‚Äôs note: The <a href="https://github.com/CyberCat-Institute/open-game-engine/blob/master/src/OpenGames/Engine/BayesianGames.hs">‚Äústateful Bayesian‚Äù backend</a> eventually became the default backend of the open game engine.<a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>
    </section>
</article>

        </main>

        <footer>
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </footer>
    </body>
</html>
